{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy vs Torch vs MLX\n",
    "\n",
    "In the world of transformers, one needs to have a firm understanding of their building blocks, which boils down to matrix maths... \n",
    "\n",
    "NumPy is the go-to library for mathematics with python and uses `numpy.arry`, PyTorch is Facebook with `torch.tensor` and apple have now released their framework mlx with `mlx.core.array`. \n",
    "\n",
    "Due to the size of the matrices that we use in deep learning models, we end up performing millions, sometimes billions of (simple) calculations. It therefore becomes advisable to accelerate this with our systems GPU. While the industry standard is Nvidia CUDA, this is only available to intel based systems. Torch allows you to hand off calculations to the graphics chip by specifying `cuda` as the device. Apple has recently moved away from intel based hardware to its own proprietary Apple Silicon chips. While Torch can accelerate with `mps`, apple recently released their MLX library that is built to fully utilise Apple Silicon. \n",
    "\n",
    "This repository is going to investigate just how beneficial switching to the MLX library would be for the development of smaller local models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlx.core as mx\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3], dtype=int32), tensor([1, 2, 3]), array([1, 2, 3]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How do we define arrays with each library?\n",
    "\n",
    "a = mx.array([1, 2, 3])\n",
    "b = torch.tensor([1, 2, 3])\n",
    "c = np.array([1, 2, 3])\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0.25, 0.5, 0.75, 1], dtype=float32),\n",
       " tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000]),\n",
       " array([0.  , 0.25, 0.5 , 0.75, 1.  ]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = mx.linspace(0, 1, 5)\n",
    "b = torch.linspace(0, 1, 5)\n",
    "c = np.linspace(0, 1, 5)\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mx.arange(48).reshape(3, 4, 4)\n",
    "b = torch.arange(48).reshape(3, 4, 4)\n",
    "c = np.arange(48).reshape(3, 4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Broadcasting\n",
    "\n",
    "So - what is an array, and does it behave?\n",
    "NumPy compares their shapes element-wise. Starting with the trailing dimensions and works its way left. Two elements are compatible when:\n",
    "1. They are equal\n",
    "2. one of them is 1\n",
    "\n",
    "**Example**  \n",
    "The following 2 six dimension shapes are compatible  \n",
    "Shape 1: (1, 6, 4, 1, 7, 2)  \n",
    "Shape 2: (5, 6, 1, 3, 1, 2)  \n",
    "Because each dimension follows that rules above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((6, 5))\n",
    "b = np.arange(5).reshape((1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((6, 5))\n",
    "b = torch.arange(5).reshape((1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mx.ones((6, 5))\n",
    "b = mx.arange(5).reshape((1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling by different amounts\n",
    "The arrays/tensors dont need to have the same number of dimensions. If one of the arrays/tensors has fewer dimensions than the other. \n",
    "\n",
    "**Example**  \n",
    "Scaling each other the colour channels of an image by a different amount.  \n",
    "\n",
    "Image  (3D array): 256 x 256 x 3  \n",
    "scale  (1D array):             3  \n",
    "Result (3D array): 256 x 256 x 3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.rand((256, 256, 3))\n",
    "scale = torch.tensor([0.5, 1.5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = image * scale\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.random.rand(256, 256, 3)\n",
    "scale = np.array([0.5, 1.5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = image * scale\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mx.random.normal((256, 256, 3))\n",
    "scale = mx.array([0.5, 1.5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[256, 256, 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = image * scale\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**  \n",
    "One has an array of 2 images and wants to scale the colour channels of each image by slightly different amounts:  \n",
    "\n",
    "Image  (3D array): 2 x 256 x 256 x 3  \n",
    "scale  (1D array): 2 x  1  x  1  x 3  \n",
    "Result (3D array): 2 x 256 x 256 x 3  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mx.random.normal((2, 256, 256, 3))\n",
    "scales = mx.array([0.5, 1.5, 1, 1.5, 1, 0.5]).reshape((2,1, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 256, 256, 3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = image * scale\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations Across Dimensions\n",
    "\n",
    "Fundamental to these libraries is the ability to operate across dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.1250), tensor(1.6520), tensor(4.), tensor(0.5000))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## in 1 Dimension\n",
    "t = torch.tensor([0.5, 1, 3, 4])\n",
    "torch.mean(t), torch.std(t), torch.max(t), torch.min(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.125, 1.4306903927824497, 4.0, 0.5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.array([0.5, 1, 3, 4])\n",
    "np.mean(n), np.std(n), np.max(n), np.min(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(2.125, dtype=float32),\n",
       " array(1.43069, dtype=float32),\n",
       " array(4, dtype=float32),\n",
       " array(0.5, dtype=float32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = mx.array([0.5, 1, 3, 4])\n",
    "## std is not available so we have to compute ourselves.\n",
    "m.mean(), (sum((m.mean()-m)**2)/len(m))**0.5, m.max(), m.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about operations on a multi-dimensional array/tensor?\n",
    "Taking the mean of each column is referred to as \"taking the mean across the rows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]], dtype=torch.float64),\n",
       " tensor([ 8.,  9., 10., 11.], dtype=torch.float64))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(20, dtype=float).reshape(5, 4)\n",
    "t, torch.mean(t, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.],\n",
       "        [16., 17., 18., 19.]]),\n",
       " array([ 8.,  9., 10., 11.]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(20, dtype=float).reshape(5, 4)\n",
    "a, a.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2, 3],\n",
       "        [4, 5, 6, 7],\n",
       "        [8, 9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]], dtype=int32),\n",
       " array([8, 9, 10, 11], dtype=float32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = mx.arange(20).reshape(5, 4)\n",
    "m, m.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This can also be done for higher dimensional arrays/tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(5, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(t, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256, 256])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(t, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indx = torch.max(t, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are they different?\n",
    "\n",
    "**Pytorch** begins to differ away from **NumPy** when computing gradients of operations. \n",
    "\n",
    "$ y = \\sum\\limits_{i} x^{3}_{i}$  \n",
    "\n",
    "has a gradient  \n",
    "\n",
    "$ \\frac{\\partial y}{\\partial x_i} = 3 x^{2}_{i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 8.],\n",
       "        [4., 6.]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[5., 8.], [4., 6.]], requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(917., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.pow(3).sum()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 75., 192.],\n",
       "        [ 48., 108.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward() ## compute the gradient\n",
    "x.grad ## print the gradient (everything that has happened to x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 75., 192.],\n",
       "        [ 48., 108.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is not available in NumPy or MLX.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch to MLX\n",
    "PyTorch supports the buffer protocol, but required an explicit `memoryview`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
